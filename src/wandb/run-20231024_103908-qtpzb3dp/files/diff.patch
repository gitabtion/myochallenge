diff --git a/src/train/dummy_vec_env.py b/src/train/dummy_vec_env.py
new file mode 100644
index 0000000..3bc7eb1
--- /dev/null
+++ b/src/train/dummy_vec_env.py
@@ -0,0 +1,155 @@
+from collections import OrderedDict
+from copy import deepcopy
+from typing import Any, Callable, List, Optional, Sequence, Type, Union
+
+import gym
+import numpy as np
+
+from stable_baselines3.common.vec_env.base_vec_env import VecEnv, VecEnvIndices, VecEnvObs, VecEnvStepReturn
+from stable_baselines3.common.vec_env.util import copy_obs_dict, dict_to_obs, obs_space_info
+
+
+class DummyVecEnv(VecEnv):
+    """
+    Creates a simple vectorized wrapper for multiple environments, calling each environment in sequence on the current
+    Python process. This is useful for computationally simple environment such as ``cartpole-v1``,
+    as the overhead of multiprocess or multithread outweighs the environment computation time.
+    This can also be used for RL methods that
+    require a vectorized environment, but that you want a single environments to train with.
+
+    :param env_fns: a list of functions
+        that return environments to vectorize
+    :raises ValueError: If the same environment instance is passed as the output of two or more different env_fn.
+    """
+
+    def __init__(self, env_fns: List[Callable[[], gym.Env]]):
+        self.envs = [fn() for fn in env_fns]
+        if len(set([id(env.unwrapped) for env in self.envs])) != len(self.envs):
+            raise ValueError(
+                "You tried to create multiple environments, but the function to create them returned the same instance "
+                "instead of creating different objects. "
+                "You are probably using `make_vec_env(lambda: env)` or `DummyVecEnv([lambda: env] * n_envs)`. "
+                "You should replace `lambda: env` by a `make_env` function that "
+                "creates a new instance of the environment at every call "
+                "(using `gym.make()` for instance). You can take a look at the documentation for an example. "
+                "Please read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information."
+            )
+        env = self.envs[0]
+        VecEnv.__init__(self, len(env_fns), env.observation_space, env.action_space)
+        obs_space = env.observation_space
+        self.keys, shapes, dtypes = obs_space_info(obs_space)
+
+        self.buf_obs = OrderedDict([(k, np.zeros((self.num_envs,) + tuple(shapes[k]), dtype=dtypes[k])) for k in self.keys])
+        self.buf_dones = np.zeros((self.num_envs,), dtype=bool)
+        self.buf_rews = np.zeros((self.num_envs,), dtype=np.float32)
+        self.buf_infos = [{} for _ in range(self.num_envs)]
+        self.actions = None
+        self.metadata = env.metadata
+
+    def step_async(self, actions: np.ndarray) -> None:
+        self.actions = actions
+
+    def step_wait(self) -> VecEnvStepReturn:
+        for env_idx in range(self.num_envs):
+            try:
+                obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
+                    self.actions[env_idx]
+                )
+            except:
+                self.buf_dones[env_idx] = True
+                obs = self.buf_obs[None][env_idx] 
+                                                   
+            if self.buf_dones[env_idx]:
+                # save final observation where user can get it, then reset
+                self.buf_infos[env_idx]["terminal_observation"] = obs 
+                # obs = self.envs[env_idx].reset()
+            self._save_obs(env_idx, obs)
+        return (self._obs_from_buf(), np.copy(self.buf_rews), np.copy(self.buf_dones), deepcopy(self.buf_infos))
+
+    def seed(self, seed: Optional[int] = None) -> List[Union[None, int]]:
+        if seed is None:
+            seed = np.random.randint(0, 2**32 - 1)
+        seeds = []
+        for idx, env in enumerate(self.envs):
+            seeds.append(env.seed(seed + idx))
+        return seeds
+
+    # def reset(self) -> VecEnvObs:
+    #     for env_idx in range(self.num_envs):
+    #         obs = self.envs[env_idx].reset()
+    #         self._save_obs(env_idx, obs)
+    #     return self._obs_from_buf()
+
+    def reset(self, env_ids, qpos, qvel) -> VecEnvObs:
+        for env_idx in env_ids:
+            _qpos = qpos[env_idx]
+            _qvel = qvel[env_idx]
+            kwargs = {'qpos': _qpos, 'qvel': _qvel}
+            obs = self.envs[env_idx].reset(**kwargs)
+            self._save_obs(env_idx, obs)
+        return self._obs_from_buf()
+
+    def close(self) -> None:
+        for env in self.envs:
+            env.close()
+
+    def get_images(self) -> Sequence[np.ndarray]:
+        return [env.render(mode="rgb_array") for env in self.envs]
+
+    def render(self, mode: str = "human") -> Optional[np.ndarray]:
+        """
+        Gym environment rendering. If there are multiple environments then
+        they are tiled together in one image via ``BaseVecEnv.render()``.
+        Otherwise (if ``self.num_envs == 1``), we pass the render call directly to the
+        underlying environment.
+
+        Therefore, some arguments such as ``mode`` will have values that are valid
+        only when ``num_envs == 1``.
+
+        :param mode: The rendering type.
+        """
+        if self.num_envs == 1:
+            return self.envs[0].render(mode=mode)
+        else:
+            return super().render(mode=mode)
+
+    def _save_obs(self, env_idx: int, obs: VecEnvObs) -> None:
+        for key in self.keys:
+            if key is None:
+                self.buf_obs[key][env_idx] = obs
+            else:
+                self.buf_obs[key][env_idx] = obs[key]
+
+    def _obs_from_buf(self) -> VecEnvObs:
+        return dict_to_obs(self.observation_space, copy_obs_dict(self.buf_obs))
+
+    def get_attr(self, attr_name: str, indices: VecEnvIndices = None) -> List[Any]:
+        """Return attribute from vectorized environment (see base class)."""
+        target_envs = self._get_target_envs(indices)
+        return [getattr(env_i, attr_name) for env_i in target_envs]
+
+    def set_attr(self, attr_name: str, value: Any, indices: VecEnvIndices = None) -> None:
+        """Set attribute inside vectorized environments (see base class)."""
+        target_envs = self._get_target_envs(indices)
+        for env_i in target_envs:
+            setattr(env_i, attr_name, value)
+
+    def env_method(self, method_name: str, *method_args, indices: VecEnvIndices = None, **method_kwargs) -> List[Any]:
+        """Call instance methods of vectorized environments."""
+        target_envs = self._get_target_envs(indices)
+        return [getattr(env_i, method_name)(*method_args, **method_kwargs) for env_i in target_envs]
+
+    def env_is_wrapped(self, wrapper_class: Type[gym.Wrapper], indices: VecEnvIndices = None) -> List[bool]:
+        """Check if worker environments are wrapped with a given wrapper"""
+        target_envs = self._get_target_envs(indices)
+        # Import here to avoid a circular import
+        from stable_baselines3.common import env_util
+
+        return [env_util.is_wrapped(env_i, wrapper_class) for env_i in target_envs]
+
+    def _get_target_envs(self, indices: VecEnvIndices) -> List[gym.Env]:
+        indices = self._get_indices(indices)
+        return [self.envs[i] for i in indices]
+    
+    
+
diff --git a/src/train/subproc_mutil_vec_env.py b/src/train/subproc_mutil_vec_env.py
new file mode 100644
index 0000000..3a54d3b
--- /dev/null
+++ b/src/train/subproc_mutil_vec_env.py
@@ -0,0 +1,284 @@
+import multiprocessing as mp
+from collections import OrderedDict
+from typing import Any, Callable, List, Optional, Sequence, Tuple, Type, Union
+from stable_baselines3.common.vec_env.util import copy_obs_dict, dict_to_obs, obs_space_info
+import gym
+from copy import deepcopy
+import numpy as np
+from gym import spaces
+
+from stable_baselines3.common.vec_env.base_vec_env import (
+    CloudpickleWrapper,
+    VecEnv,
+    VecEnvIndices,
+    VecEnvObs,
+    VecEnvStepReturn,
+)
+
+
+def _worker(
+    remote: mp.connection.Connection, parent_remote: mp.connection.Connection, env_fn_wrapper: CloudpickleWrapper
+) -> None:
+    # Import here to avoid a circular import
+    from stable_baselines3.common.env_util import is_wrapped
+
+    parent_remote.close()
+    env = env_fn_wrapper.var# ()
+    # TODO: 所有的 env 都指代 DummyVecEnv
+    while True:
+        try:
+            cmd, data = remote.recv()
+            # print(data)
+            if cmd == "step":
+                observation, reward, done, info = env.step(data)
+                remote.send((observation, reward, done, info))
+            elif cmd == "seed":
+                remote.send(env.seed(data))
+            elif cmd == "reset":
+                observation = env.reset(**data)
+                remote.send(observation)
+            elif cmd == "render":
+                remote.send(env.render(data))
+            elif cmd == "close":
+                env.close()
+                remote.close()
+                break
+            elif cmd == "get_spaces":
+                remote.send((env.envs[0].observation_space, env.envs[0].action_space))
+            elif cmd == "env_method":
+                method = env.env_method(data[0]) # getattr(env, data[0])
+                remote.send(method)
+            elif cmd == "get_attr":
+                attr = env.get_attr(data)
+                remote.send(attr)
+            elif cmd == "set_attr":
+                # remote.send(setattr(env, data[0], data[1]))
+                remote.send(env.set_attr(data[0], data[1]))
+            elif cmd == "is_wrapped":
+                remote.send(is_wrapped(env, data))
+            elif cmd == "get_frame":
+                frame = env.env.sim.renderer.render_offscreen(width=640, height=480,camera_id='1')
+                remote.send(frame)
+            else:
+                raise NotImplementedError(f"`{cmd}` is not implemented in the worker")
+        except EOFError:
+            break
+
+
+class SubprocMutilVecEnv(VecEnv):
+    def __init__(self, env_fns, work_groups, num_envs, start_method=None):
+        self.waiting = False
+        self.closed = False
+        self.n_envs = num_envs
+        self.n_works = work_groups
+
+        if start_method is None:
+            forkserver_available = "forkserver" in mp.get_all_start_methods()
+            start_method = "forkserver" if forkserver_available else "spawn"
+        ctx = mp.get_context(start_method)
+
+        self.remotes, self.work_remotes = zip(*[ctx.Pipe() for _ in range(self.n_works)])
+        self.processes = []
+        for work_remote, remote, env_fn in zip(self.work_remotes, self.remotes, env_fns):
+            args = (work_remote, remote, CloudpickleWrapper(env_fn))
+            # daemon=True: if the main process crashes, we should not cause things to hang
+            process = ctx.Process(target=_worker, args=args, daemon=True)  # pytype:disable=attribute-error
+            process.start()
+            self.processes.append(process)
+            work_remote.close()
+
+        self.remotes[0].send(("get_spaces", None))
+        observation_space, action_space = self.remotes[0].recv()
+        self.observation_space, self.action_space = observation_space, action_space
+        # print(observation_space, action_space)
+        VecEnv.__init__(self, len(env_fns), observation_space, action_space)
+        self.keys, shapes, dtypes = obs_space_info(observation_space)
+        self.buf_obs = OrderedDict([(k, np.zeros((self.n_works, self.n_envs) + tuple(shapes[k]), dtype=dtypes[k])) for k in self.keys])
+        self.buf_dones = np.zeros((self.n_works, self.n_envs), dtype=bool)
+        self.buf_rews = np.zeros((self.n_works, self.n_envs), dtype=np.float32)
+        self.buf_infos = [[{} for _ in range(self.n_envs)] for _ in range(self.n_works)]
+        self.actions = None
+        self.remotes[0].send(("get_attr", "metadata"))
+        self.metadata = self.remotes[0].recv()
+        self.boundaries = [n * self.n_envs for n in range(self.n_works)]
+
+    def _save_obs(self, env_idx: int, obs: VecEnvObs) -> None:
+        # TODO: 是否需维护两个队列(内外)?
+        for key in self.keys:
+            if key is None:
+                self.buf_obs[key][env_idx] = obs
+            else:
+                self.buf_obs[key][env_idx] = obs[key]
+    
+    def step_async(self, actions: np.ndarray) -> None:
+        actions = actions.reshape(self.n_works, self.n_envs, -1)
+        for remote, action in zip(self.remotes, actions):
+            remote.send(("step", action))
+        self.waiting = True
+
+    def step_wait(self) -> VecEnvStepReturn:
+        for index, remote in enumerate(self.remotes):
+            obs, self.buf_rews[index], self.buf_dones[index], self.buf_infos[index] = remote.recv()
+            self._save_obs(index, obs)          
+        
+        self.waiting = False
+        obs_ = self._obs_from_buf() # .reshape(-1, obs.shape(-1))
+        obs_ = obs_.reshape(-1, self.observation_space.shape[0])
+        rews_ = np.copy(self.buf_rews.flatten())
+        dones_ = np.copy(self.buf_dones.flatten())
+        info_ = deepcopy([j for i in self.buf_infos for j in i])
+        # TODO: 是否需要合并？或者有更好的解决方案， 切记联系DummyEnv再进行更改
+        return (obs_, rews_, dones_, info_)
+        
+    def seed(self, seed: Optional[int] = None) -> List[Union[None, int]]:
+        if seed is None:
+            seed = np.random.randint(0, 2**32 - 1)
+        for idx, remote in enumerate(self.remotes):
+            remote.send(("seed", seed + idx))
+        return [remote.recv() for remote in self.remotes]
+    
+    def reset(self, env_ids, qpos, qvel) -> VecEnvObs:
+        qpos = qpos.reshape(self.n_works, self.n_envs, -1)
+        qvel = qvel.reshape(self.n_works, self.n_envs, -1)
+        # TODO: env_ids 是不规则的, 无法直接 reshape, qpos, qvel 是 tensor 直接传到下一层 由下一层直接操作避免重复
+        # TODO: 目前初步想法先进行分桶操作， 对于 env_ids 进行分桶， 然后按照索引去分割qpos, qvel 再分别 seed 到每个进程中
+        env_ids_buckets = np.digitize(env_ids, self.boundaries)
+        _, indices = np.unique(env_ids_buckets, return_inverse=True)
+        split_indices = np.split(np.arange(len(env_ids_buckets)), np.cumsum(np.bincount(indices))[:-1])
+        env_ids_lists_ = [env_ids[i] for i in split_indices]
+        env_ids_lists = []
+        j_bon = 0
+        # TODO: 复杂度较高 O(n) 每次运行比较耗时 
+        for i in range(self.n_works):
+            if j_bon>=len(env_ids_lists_) or len(env_ids)==0:
+                env_ids_lists.append(np.array([]))
+            else:
+                if (env_ids_lists_[j_bon].max() < ((i + 1) * self.n_envs)):
+                    env_ids_lists.append(env_ids_lists_[j_bon] - (i * self.n_envs))
+                    j_bon += 1
+                else:
+                    env_ids_lists.append(np.array([]))
+        for index, remote in zip(range(self.n_works), self.remotes):
+            _qpos = qpos[index]
+            _qvel = qvel[index]
+            env_ids_part = env_ids_lists[index]
+            kwargs = {'qpos': _qpos, 'qvel': _qvel, "env_ids": env_ids_part}
+            remote.send(("reset", kwargs))
+            obs = remote.recv()
+            self._save_obs(index, obs)
+        obs_ = self._obs_from_buf()
+        obs_ = obs_.reshape(-1, self.observation_space.shape[0])
+        return obs_
+
+    def _obs_from_buf(self) -> VecEnvObs:
+        return dict_to_obs(self.observation_space, copy_obs_dict(self.buf_obs))
+    
+    def close(self) -> None:
+        if self.closed:
+            return
+        if self.waiting:
+            for remote in self.remotes:
+                remote.recv()
+        for remote in self.remotes:
+            remote.send(("close", None))
+        for process in self.processes:
+            process.join()
+        self.closed = True
+
+    # def get_images(self) -> Sequence[np.ndarray]:
+    #     # for pipe in self.remotes:
+    #     #     # gather images from subprocesses
+    #     #     # `mode` will be taken into account later
+    #     self.remotes[0].send(("render", "rgb_array"))
+    #     imgs = self.remotes[0].recv() # [pipe.recv() for pipe in self.remotes]
+    #     return imgs
+
+    def get_attr(self, attr_name: str, indices: VecEnvIndices = None) -> List[Any]:
+        """Return attribute from vectorized environment (see base class)."""
+        target_remotes = self._get_target_remotes(indices)
+        # print("BB", target_remotes)
+        # attr_name = attr_name.split("+")
+        for remote in target_remotes:
+            remote.send(("get_attr", attr_name))
+        return [remote.recv() for remote in target_remotes]
+    
+    def get_frame(self):
+        remotes = self.remotes[0]
+        remotes.send(("get_frame", ()))
+        return remotes.recv()
+    
+    def render(self, mode: str = "human") -> Optional[np.ndarray]:
+        """
+        Gym environment rendering. If there are multiple environments then
+        they are tiled together in one image via ``BaseVecEnv.render()``.
+        Otherwise (if ``self.num_envs == 1``), we pass the render call directly to the
+        underlying environment.
+
+        Therefore, some arguments such as ``mode`` will have values that are valid
+        only when ``num_envs == 1``.
+
+        :param mode: The rendering type.
+        """
+        if self.num_envs == 1:
+            return self.envs[0].render(mode=mode)
+        else:
+            return super().render(mode=mode)
+
+    def set_attr(self, attr_name: str, value: Any, indices: VecEnvIndices = None) -> None:
+        """Set attribute inside vectorized environments (see base class)."""
+        target_remotes = self._get_target_remotes(indices)
+        for remote in target_remotes:
+            remote.send(("set_attr", (attr_name, value)))
+        for remote in target_remotes:
+            remote.recv()
+
+    def env_method(self, method_name: str, *method_args, indices: VecEnvIndices = None, **method_kwargs) -> List[Any]:
+        """Call instance methods of vectorized environments."""
+        target_remotes = self._get_target_remotes(indices)
+        for remote in target_remotes:
+            remote.send(("env_method", (method_name, method_args, method_kwargs)))
+        return [j for i in [remote.recv() for remote in target_remotes] for j in i]
+
+    def env_is_wrapped(self, wrapper_class: Type[gym.Wrapper], indices: VecEnvIndices = None) -> List[bool]:
+        """Check if worker environments are wrapped with a given wrapper"""
+        target_remotes = self._get_target_remotes(indices)
+        for remote in target_remotes:
+            remote.send(("is_wrapped", wrapper_class))
+        return [remote.recv() for remote in target_remotes]
+
+    def _get_target_remotes(self, indices: VecEnvIndices) -> List[Any]:
+        """
+        Get the connection object needed to communicate with the wanted
+        envs that are in subprocesses.
+
+        :param indices: refers to indices of envs.
+        :return: Connection object to communicate between processes.
+        """
+        indices = self._get_indices(indices)
+        return [self.remotes[i] for i in indices]
+
+
+def _flatten_obs(obs: Union[List[VecEnvObs], Tuple[VecEnvObs]], space: spaces.Space) -> VecEnvObs:
+    """
+    Flatten observations, depending on the observation space.
+
+    :param obs: observations.
+                A list or tuple of observations, one per environment.
+                Each environment observation may be a NumPy array, or a dict or tuple of NumPy arrays.
+    :return: flattened observations.
+            A flattened NumPy array or an OrderedDict or tuple of flattened numpy arrays.
+            Each NumPy array has the environment index as its first axis.
+    """
+    assert isinstance(obs, (list, tuple)), "expected list or tuple of observations per environment"
+    assert len(obs) > 0, "need observations from at least one environment"
+
+    if isinstance(space, spaces.Dict):
+        assert isinstance(space.spaces, OrderedDict), "Dict space must have ordered subspaces"
+        assert isinstance(obs[0], dict), "non-dict observation for environment with Dict observation space"
+        return OrderedDict([(k, np.stack([o[k] for o in obs])) for k in space.spaces.keys()])
+    elif isinstance(space, spaces.Tuple):
+        assert isinstance(obs[0], tuple), "non-tuple observation for environment with Tuple observation space"
+        obs_len = len(space.spaces)
+        return tuple(np.stack([o[i] for o in obs]) for i in range(obs_len))
+    else:
+        return np.stack(obs)
diff --git a/src/train/subproc_ray_vec_env.py b/src/train/subproc_ray_vec_env.py
new file mode 100644
index 0000000..026d6a2
--- /dev/null
+++ b/src/train/subproc_ray_vec_env.py
@@ -0,0 +1,246 @@
+from collections import OrderedDict
+from typing import Any, Callable, List, Optional, Sequence, Tuple, Type, Union
+from stable_baselines3.common.vec_env.util import copy_obs_dict, dict_to_obs, obs_space_info
+import gym
+from copy import deepcopy
+import numpy as np
+import ray
+# ray.init()
+from stable_baselines3.common.vec_env.base_vec_env import (
+    VecEnv,
+    VecEnvIndices,
+    VecEnvObs,
+    VecEnvStepReturn,
+)
+
+
+@ray.remote
+class DummyVecEnv():
+    def __init__(self, env_fns: List[Callable[[], gym.Env]]):
+        self.envs = env_fns
+        self.env = self.envs[0]
+        self.num_envs = len(env_fns)
+        # VecEnv.__init__(self, len(env_fns), self.env.observation_space, self.env.action_space)
+        self.observation_space = self.env.observation_space
+        self.action_space = self.env.action_space
+        self.keys, shapes, dtypes = obs_space_info(self.observation_space)
+        self.buf_obs = OrderedDict([(k, np.zeros((self.num_envs,) + tuple(shapes[k]), dtype=dtypes[k])) for k in self.keys])
+        self.buf_dones = np.zeros((self.num_envs,), dtype=bool)
+        self.buf_rews = np.zeros((self.num_envs,), dtype=np.float32)
+        self.buf_infos = [{} for _ in range(self.num_envs)]
+        self.actions = None
+        self.metadata = self.env.metadata
+
+    def get_env(self):
+        return self.env
+
+    def step(self, actions) -> VecEnvStepReturn:
+        self.actions = actions
+        for env_idx in range(self.num_envs):
+            try:
+                obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
+                    actions[env_idx]
+                )
+            except:
+                self.buf_dones[env_idx] = True
+                obs = self.buf_obs[None][env_idx] 
+                                                   
+            if self.buf_dones[env_idx]:
+                # save final observation where user can get it, then reset
+                self.buf_infos[env_idx]["terminal_observation"] = obs 
+                # obs = self.envs[env_idx].reset()
+            self._save_obs(env_idx, obs)
+        return (self._obs_from_buf(), np.copy(self.buf_rews), np.copy(self.buf_dones), deepcopy(self.buf_infos))
+
+    def seed(self, seed: Optional[int] = None) -> List[Union[None, int]]:
+        if seed is None:
+            seed = np.random.randint(0, 2**32 - 1)
+        seeds = []
+        for idx, env in enumerate(self.envs):
+            seeds.append(env.seed(seed + idx))
+        return seeds
+
+    def reset(self, env_ids, qpos, qvel) -> VecEnvObs:
+        for env_idx in env_ids:
+            _qpos = qpos[env_idx]
+            _qvel = qvel[env_idx]
+            kwargs = {'qpos': _qpos, 'qvel': _qvel}
+            obs = self.envs[env_idx].reset(**kwargs)
+            self._save_obs(env_idx, obs)
+        return self._obs_from_buf()
+
+    def close(self) -> None:
+        for env in self.envs:
+            env.close()
+        return 
+
+    def get_images(self) -> Sequence[np.ndarray]:
+        return [env.render(mode="rgb_array") for env in self.envs]
+
+    def render(self, mode: str = "human") -> Optional[np.ndarray]:
+        if self.num_envs == 1:
+            return self.envs[0].render(mode=mode)
+        else:
+            return super().render(mode=mode)
+
+    def _save_obs(self, env_idx: int, obs: VecEnvObs) -> None:
+        for key in self.keys:
+            if key is None:
+                self.buf_obs[key][env_idx] = obs
+            else:
+                self.buf_obs[key][env_idx] = obs[key]
+
+    def _obs_from_buf(self) -> VecEnvObs:
+        return dict_to_obs(self.observation_space, copy_obs_dict(self.buf_obs))
+
+    def get_attr(self, attr_name: str, indices: VecEnvIndices = None) -> List[Any]:
+        """Return attribute from vectorized environment (see base class)."""
+        target_envs = self._get_target_envs(indices)
+        return [getattr(env_i, attr_name) for env_i in target_envs]
+
+    def set_attr(self, attr_name: str, value: Any, indices: VecEnvIndices = None) -> None:
+        """Set attribute inside vectorized environments (see base class)."""
+        target_envs = self._get_target_envs(indices)
+        for env_i in target_envs:
+            setattr(env_i, attr_name, value)
+        return
+
+    def env_method(self, method_name: str, *method_args, indices: VecEnvIndices = None, **method_kwargs) -> List[Any]:
+        """Call instance methods of vectorized environments."""
+        target_envs = self._get_target_envs(indices)
+        return [getattr(env_i, method_name)() for env_i in target_envs]
+
+    def env_is_wrapped(self, wrapper_class: Type[gym.Wrapper], indices: VecEnvIndices = None) -> List[bool]:
+        """Check if worker environments are wrapped with a given wrapper"""
+        target_envs = self._get_target_envs(indices)
+        # Import here to avoid a circular import
+        from stable_baselines3.common import env_util
+
+        return [env_util.is_wrapped(env_i, wrapper_class) for env_i in target_envs]
+
+    def _get_target_envs(self, indices: VecEnvIndices) -> List[gym.Env]:
+        # indices = self._get_indices(indices)
+        return self.envs
+
+
+class SubRayVecEnv():
+    def __init__(self, env_name, work_groups, num_envs):
+        self.waiting = False
+        self.closed = False
+        self.n_envs = num_envs
+        self.n_works = work_groups
+        self.envs = [DummyVecEnv.remote(self.create_env(env_id=env_name, n_envs=self.n_envs)) for _ in range(self.n_works)]
+        self.single_env = ray.get(self.envs[0].get_env.remote())
+        self.observation_space, self.action_space = self.single_env.observation_space, self.single_env.action_space
+        # VecEnv.__init__(self, len(self.envs), self.observation_space, self.action_space)
+        self.keys, shapes, dtypes = obs_space_info(self.observation_space)
+        self.buf_obs = OrderedDict([(k, np.zeros((self.n_works, self.n_envs) + tuple(shapes[k]), dtype=dtypes[k])) for k in self.keys])
+        self.buf_dones = np.zeros((self.n_works, self.n_envs), dtype=bool)
+        self.buf_rews = np.zeros((self.n_works, self.n_envs), dtype=np.float32)
+        self.buf_infos = [[{} for _ in range(self.n_envs)] for _ in range(self.n_works)]
+        self.actions = None
+        self.metadata = ray.get(self.envs[0].get_attr.remote("metadata"))
+        self.boundaries = [n * self.n_envs for n in range(self.n_works)]
+    
+    def create_env(
+            self, 
+            env_id,
+            n_envs,
+            seed=None,
+            start_index=0,
+            env_kwargs=None,
+        ):
+        env_kwargs = {} if env_kwargs is None else env_kwargs
+        env_list = [gym.make(env_id, **env_kwargs) for i in range(n_envs)]
+        return env_list
+
+    def _save_obs(self, env_idx: int, obs: VecEnvObs) -> None:
+        # TODO: 是否需维护两个队列(内外)?
+        for key in self.keys:
+            if key is None:
+                self.buf_obs[key][env_idx] = obs
+            else:
+                self.buf_obs[key][env_idx] = obs[key]
+
+    def step(self, actions: np.ndarray) -> VecEnvStepReturn:
+        actions = actions.reshape(self.n_works, self.n_envs, -1)
+        for (index, remote), act in zip(enumerate(self.envs), actions):
+            obs, self.buf_rews[index], self.buf_dones[index], self.buf_infos[index] = ray.get(remote.step.remote(act))
+            self._save_obs(index, obs)          
+        
+        self.waiting = False
+        obs_ = self._obs_from_buf() # .reshape(-1, obs.shape(-1))
+        obs_ = obs_.reshape(-1, self.observation_space.shape[0])
+        rews_ = np.copy(self.buf_rews.flatten())
+        dones_ = np.copy(self.buf_dones.flatten())
+        info_ = deepcopy([j for i in self.buf_infos for j in i])
+        return (obs_, rews_, dones_, info_)
+        
+    def seed(self, seed: Optional[int] = None) -> List[Union[None, int]]:
+        if seed is None:
+            seed = np.random.randint(0, 2**32 - 1)
+        res_list = []
+        for idx, remote in enumerate(self.envs):
+            res = ray.get(remote.seed.remote(seed + idx))
+            res_list.append(res)
+        return [j for i in res_list for j in i]
+    
+    def reset(self, env_ids, qpos, qvel) -> VecEnvObs:
+        qpos = qpos.reshape(self.n_works, self.n_envs, -1)
+        qvel = qvel.reshape(self.n_works, self.n_envs, -1)
+        # TODO: env_ids 是不规则的, 无法直接 reshape, qpos, qvel 是 tensor 直接传到下一层 由下一层直接操作避免重复
+        # TODO: 目前初步想法先进行分桶操作， 对于 env_ids 进行分桶， 然后按照索引去分割qpos, qvel 再分别 seed 到每个进程中
+        env_ids_buckets = np.digitize(env_ids, self.boundaries)
+        _, indices = np.unique(env_ids_buckets, return_inverse=True)
+        split_indices = np.split(np.arange(len(env_ids_buckets)), np.cumsum(np.bincount(indices))[:-1])
+        env_ids_lists_ = [env_ids[i] for i in split_indices]
+        env_ids_lists = []
+        j_bon = 0
+        # TODO: 复杂度较高 O(n) 每次运行比较耗时 
+        for i in range(self.n_works):
+            if j_bon>=len(env_ids_lists_) or len(env_ids)==0:
+                env_ids_lists.append(np.array([]))
+            else:
+                if (env_ids_lists_[j_bon].max() < ((i + 1) * self.n_envs)):
+                    env_ids_lists.append(env_ids_lists_[j_bon] - (i * self.n_envs))
+                    j_bon += 1
+                else:
+                    env_ids_lists.append(np.array([]))
+        for index, remote in zip(range(self.n_works), self.envs):
+            _qpos = qpos[index]
+            _qvel = qvel[index]
+            env_ids_part = env_ids_lists[index]
+            kwargs = {'qpos': _qpos, 'qvel': _qvel, "env_ids": env_ids_part}
+            # remote.send(("reset", kwargs))
+            obs = ray.get(remote.reset.remote(**kwargs)) # remote.recv()
+            self._save_obs(index, obs)
+        obs_ = self._obs_from_buf()
+        obs_ = obs_.reshape(-1, self.observation_space.shape[0])
+        return obs_
+
+    def _obs_from_buf(self) -> VecEnvObs:
+        return dict_to_obs(self.observation_space, copy_obs_dict(self.buf_obs))
+
+    def get_attr(self, attr_name: str, indices: VecEnvIndices = None) -> List[Any]:
+        """Return attribute from vectorized environment (see base class)."""
+        res_list = []
+        for remote in self.envs:
+            res = ray.get(remote.get_attr.remote(attr_name))
+            res_list.append(res)
+        return [j for i in res_list for j in i]
+    
+    def get_frame(self):
+        remotes = self.envs[0].get_images.remote()
+        frame = ray.get(remotes)[0]
+        return frame
+
+    def set_attr(self, attr_name: str, value: Any, indices: VecEnvIndices = None) -> None:
+        for remote in self.envs:
+            ray.get(remote.set_attr.remote(attr_name, value))
+
+    def env_method(self, method_name: str, *method_args, indices: VecEnvIndices = None, **method_kwargs) -> List[Any]:
+        """Call instance methods of vectorized environments."""
+        res_list = []
+        for remote in self.envs:
+            res_list.append(ray.get(remote.env_method.remote(method_name, method_args, method_kwargs)))
+        return [j for i in res_list for j in i]
\ No newline at end of file
diff --git a/src/wandb/latest-run b/src/wandb/latest-run
index 57990dd..d312331 120000
--- a/src/wandb/latest-run
+++ b/src/wandb/latest-run
@@ -1 +1 @@
-run-20231020_192656-pr0q3vjd
\ No newline at end of file
+run-20231024_103908-qtpzb3dp
\ No newline at end of file
